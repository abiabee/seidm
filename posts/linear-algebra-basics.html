<p>Linear algebra is the language of modern data. We start with a vector <em>v</em> âˆˆ â„<sup>n</sup>, then build to matrices that <strong>transform</strong> those vectors. A matrix <em>A</em> applies a linear map: <code>y = AÂ·x</code>.</p>
<h3>Spans and Bases</h3>
<p>The <em>span</em> of vectors is every combination you can reach. Choose a basis to coordinate your space â€” then a matrix is just a basis-aware machine.</p>
<blockquote>ğŸš© Tip: a matrix column is where the basis vector goes.</blockquote>
<img src="https://images.unsplash.com/photo-1529336953121-ad5a95f1d2f8?q=80&w=1200&auto=format&fit=crop" alt="Matrix concept art" />
<h3>From Math to ML</h3>
<p>In ML, weight matrices transform features. Training nudges entries of <em>A</em> so predictions match targets. Gradients flow; matrices learn.</p>
<p class="muted">Footnote markers like <sup id="fnref-1"><a href="#fn-1">[1]</a></sup> and <sup id="fnref-2"><a href="#fn-2">[2]</a></sup>.</p>
<hr/>
<ol>
  <li id="fn-1">A basis is any set of independent vectors that spans the space. <a href="#fnref-1">â†©</a></li>
  <li id="fn-2">Matrix multiplication composes linear maps. <a href="#fnref-2">â†©</a></li>
</ol>
